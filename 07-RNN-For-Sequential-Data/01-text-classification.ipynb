{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영화 리뷰 감정 분석\n",
    "**Recurrent Neural Network (RNN) 을 이용해 IMDB 데이터를 가지고 텍스트 감정분석을 해 봅시다.**\n",
    "\n",
    "```\n",
    "'먹기위해 산다.'\n",
    "'살기위해 먹는다.'\n",
    "```\n",
    "\n",
    "우리가 일상에서 읽고 쓰는 문서, 혹은 언어는 대표적인 순차적 데이터라고 할 수 있습니다. 위의 두 문장에서 볼 수 있듯, 언어는 단어나 문장의 순서에 큰 영향을 받으며, 이러한 언어의 특성덕에 RNN은 '자연어 처리'(Natural Language Processing) 분야에 매우 큰 부각을 나타내 왔습니다. 이번 프로젝트를 통해 자연어 처리 분야 중 가장 기본적이라고 할 수 있는 '텍스트 감정분석'(Sentiment Analysis) 을 같이 구현하고 공부해 보겠습니다.\n",
    "\n",
    "당연한 이야기겠지만, 자연어 처리를 위해선 텍스트나 언어 형태의 데이터가 필요합니다. 우리가 사용할 IMDB 데이터셋은 25,000건의 영화 리뷰를 가지고 있습니다. 각 리뷰는 다수의 영어 문장들로 이루어져 있으며, 긍정적인 영화 리뷰는 2로, 부정적인 영화 리뷰는 1로 레이블링 되어 있습니다. 영화 리뷰 데이터를 RNN 에 입력시켜 리뷰의 전체 내용을 이해하여 압축하고, 이렇게 압축된 리뷰를 기반으로 영화 리뷰가 긍정적인지 부정적인지 판단해주는 간단한 분류 모델을 구현하는 것이 이번 프로젝트의 목표입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 먼저 모델 구현과 학습에 필요한 라이브러리 들을 임포트 해 줍니다. 여기서 처음 등장하는 torchtext 는 자연어 처리 딥러닝에 쓰이는 다양한 데이터셋들을 포함하고 있으며, 데이터셋을 학습에 편한 형태로 바꿔주는 기능을 해 주는 편리한 오픈소스입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구현과 학습에 필요한 하이퍼파라미터 들을 정의해 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hyper parameters\n",
    "BATCH_SIZE = 64\n",
    "lr = 0.001\n",
    "EPOCHS = 40\n",
    "torch.manual_seed(42)\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 기반 모델 클래스 생성하기\n",
    "\n",
    "BasicLSTM 라고 하는 RNN 을 포함하는 신경망 모델을 만들어 보겠습니다. 여타 다른 신경망 모델과 같이 파이토치의 nn.Module 을 상속받습니다.\n",
    "\n",
    "```python\n",
    "class BasicLSTM(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
    "        super(BasicLSTM, self).__init__()\n",
    "        print(\"Building Basic LSTM model...\")\n",
    "```\n",
    "\n",
    "### RNN 에 필요한 패러미터 정의하기\n",
    "\n",
    "IMDB 와 같은 자연어 데이터에선 모든 단어들이 랭크 1의 텐서로 정의됩니다.\n",
    "이 때 각 단어를 나타내는 텐서 속 특성값의 수가 바로 embed 라는 변수입니다.\n",
    "영화평 속의 모든 단어들이 텐서로 나타내어 지다면, 영화평 전체는 곧 텐서의 배열이라고 할 수 있겠지요.\n",
    "\n",
    "```python\n",
    "class BasicLSTM(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
    "        super(BasicLSTM, self).__init__()\n",
    "        print(\"Building Basic LSTM model...\")\n",
    "        self.n_layers = n_layers\n",
    "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BasicRNN(nn.Module):\n",
    "#     \"\"\"\n",
    "#         Basic RNN\n",
    "#     \"\"\"\n",
    "#     def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
    "#         super(BasicRNN, self).__init__()\n",
    "#         print(\"Building Basic RNN model...\")\n",
    "#         self.n_layers = n_layers\n",
    "#         self.hidden_dim = hidden_dim\n",
    "\n",
    "#         self.embed = nn.Embedding(n_vocab, embed_dim)\n",
    "#         self.dropout = nn.Dropout(dropout_p)\n",
    "#         self.rnn = nn.RNN(embed_dim, hidden_dim, n_layers,\n",
    "#                           dropout=dropout_p, batch_first=True)\n",
    "#         self.out = nn.Linear(self.hidden_dim, n_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         embedded = self.embed(x)  #  [b, i] -> [b, i, e]\n",
    "#         _, hidden = self.rnn(embedded)\n",
    "#         self.dropout(hidden)\n",
    "#         hidden = hidden.squeeze()\n",
    "#         logit = self.out(hidden)  # [b, h] -> [b, o]\n",
    "#         return logit\n",
    "\n",
    "class BasicLSTM(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
    "        super(BasicLSTM, self).__init__()\n",
    "        print(\"Building Basic LSTM model...\")\n",
    "        self.n_layers = n_layers\n",
    "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.lstm = nn.LSTM(embed_dim, self.hidden_dim,\n",
    "                            num_layers=self.n_layers,\n",
    "                            dropout=dropout_p,\n",
    "                            batch_first=True)\n",
    "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)  #  [b, i] -> [b, i, e]\n",
    "        h_0 = self._init_state(batch_size=x.size(0))\n",
    "        x, _ = self.lstm(x, h_0)  # [i, b, h]\n",
    "        h_t = x[:,-1,:]\n",
    "        self.dropout(h_t)\n",
    "        logit = self.out(h_t)  # [b, h] -> [b, o]\n",
    "        return logit\n",
    "    \n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return (\n",
    "            weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "            weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_iter):\n",
    "    model.train()\n",
    "    for b, batch in enumerate(train_iter):\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "        y.data.sub_(1)  # index align\n",
    "        optimizer.zero_grad()\n",
    "        logit = model(x)\n",
    "        loss = F.cross_entropy(logit, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if b % 100 == 0:\n",
    "            corrects = (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
    "            accuracy = 100.0 * corrects / batch.batch_size\n",
    "            sys.stdout.write(\n",
    "                '\\rBatch[%d] - loss: %.6f  acc: %.2f' %\n",
    "                (b, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    \"\"\"evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    corrects, avg_loss = 0, 0\n",
    "    for batch in val_iter:\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "        y.data.sub_(1)  # index align\n",
    "        logit = model(x)\n",
    "        loss = F.cross_entropy(logit, y, size_average=False)\n",
    "        avg_loss += loss.item()\n",
    "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
    "    size = len(val_iter.dataset)\n",
    "    avg_loss = avg_loss / size\n",
    "    accuracy = 100.0 * corrects / size\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB 데이터셋 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "print(\"\\nLoading data...\")\n",
    "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
    "LABEL = data.Field(sequential=False, batch_first=True)\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "TEXT.build_vocab(train_data, min_freq=5)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "train_iter, test_iter = data.BucketIterator.splits(\n",
    "        (train_data, test_data), batch_size=BATCH_SIZE,\n",
    "        shuffle=True, repeat=False)\n",
    "\n",
    "vocab_size = len(TEXT.vocab)\n",
    "n_classes = len(LABEL.vocab) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]: 391 \t [TEST]: 391 \t [VOCAB] 46159 \t [CLASSES] 2\n"
     ]
    }
   ],
   "source": [
    "print(\"[TRAIN]: %d \\t [TEST]: %d \\t [VOCAB] %d \\t [CLASSES] %d\"\n",
    "      % (len(train_iter),len(test_iter), vocab_size, n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Basic LSTM model...\n",
      "BasicLSTM(\n",
      "  (embed): Embedding(46159, 128)\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (lstm): LSTM(128, 256, batch_first=True, dropout=0.5)\n",
      "  (out): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keon/.local/lib/python3.5/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "model = BasicLSTM(1, 256, vocab_size, 128, n_classes, 0.5).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = None\n",
    "for e in range(1, EPOCHS+1):\n",
    "    train(model, optimizer, train_iter)\n",
    "    val_loss, val_accuracy = evaluate(model, test_iter)\n",
    "\n",
    "    print(\"\\n[Epoch: %d] val_loss:%5.2f | acc:%5.2f\" % (e, val_loss, val_accuracy))\n",
    "    \n",
    "    # Save the model if the validation loss is the best we've seen so far.\n",
    "#     if not best_val_loss or val_loss < best_val_loss:\n",
    "#         if not os.path.isdir(\"snapshot\"):\n",
    "#             os.makedirs(\"snapshot\")\n",
    "#         torch.save(model.state_dict(), './snapshot/convcnn.pt')\n",
    "#         best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
