{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional GAN으로 생성 컨트롤하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "EPOCHS = 300\n",
    "BATCH_SIZE = 100\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"Using Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion MNIST 데이터셋\n",
    "trainset = datasets.FashionMNIST(\n",
    "    './.data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "       transforms.ToTensor(),\n",
    "       transforms.Normalize((0.5,), (0.5,))\n",
    "    ]),\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = trainset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자 (Generator)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(10, 10)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(110, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, labels):\n",
    "        c = self.embed(labels)\n",
    "        x = torch.cat([z, c], 1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판별자 (Discriminator)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(10, 10)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(794, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, labels):\n",
    "        c = self.embed(labels)\n",
    "        x = torch.cat([x, c], 1)\n",
    "        out = self.model(x)\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스를 만들고 모델의 가중치를 지정한 장치로 보내기\n",
    "D = Discriminator().to(DEVICE)\n",
    "G = Generator().to(DEVICE)\n",
    "\n",
    "# 이진 크로스 엔트로피 (Binary cross entropy) 오차 함수와\n",
    "# 생성자와 판별자를 최적화할 Adam 모듈\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=0.0002)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keon/projects/3-min-pytorch/env/lib/python3.7/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([100, 1])) that is different to the input size (torch.Size([100])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이폭 [0/300] d_loss:0.3738 g_loss: 4.4556 D(x):0.89 D(G(z)):0.16\n",
      "이폭 [1/300] d_loss:0.4419 g_loss: 3.6021 D(x):0.87 D(G(z)):0.15\n",
      "이폭 [2/300] d_loss:0.4561 g_loss: 3.0607 D(x):0.91 D(G(z)):0.18\n",
      "이폭 [3/300] d_loss:0.3792 g_loss: 4.0255 D(x):0.86 D(G(z)):0.05\n",
      "이폭 [4/300] d_loss:0.5510 g_loss: 2.6251 D(x):0.83 D(G(z)):0.18\n",
      "이폭 [5/300] d_loss:0.3710 g_loss: 2.6054 D(x):0.89 D(G(z)):0.16\n",
      "이폭 [6/300] d_loss:0.8116 g_loss: 1.6371 D(x):0.78 D(G(z)):0.30\n",
      "이폭 [7/300] d_loss:0.7591 g_loss: 2.3216 D(x):0.80 D(G(z)):0.26\n",
      "이폭 [8/300] d_loss:0.9191 g_loss: 1.3288 D(x):0.75 D(G(z)):0.33\n",
      "이폭 [9/300] d_loss:1.3485 g_loss: 1.2583 D(x):0.53 D(G(z)):0.34\n",
      "이폭 [10/300] d_loss:0.5799 g_loss: 2.2198 D(x):0.83 D(G(z)):0.22\n",
      "이폭 [11/300] d_loss:0.8559 g_loss: 1.7682 D(x):0.74 D(G(z)):0.26\n",
      "이폭 [12/300] d_loss:0.8210 g_loss: 1.6988 D(x):0.68 D(G(z)):0.25\n",
      "이폭 [13/300] d_loss:0.8274 g_loss: 1.6738 D(x):0.70 D(G(z)):0.26\n",
      "이폭 [14/300] d_loss:1.1184 g_loss: 1.3756 D(x):0.65 D(G(z)):0.34\n",
      "이폭 [15/300] d_loss:0.7997 g_loss: 1.6533 D(x):0.75 D(G(z)):0.28\n",
      "이폭 [16/300] d_loss:0.9558 g_loss: 1.4819 D(x):0.70 D(G(z)):0.31\n",
      "이폭 [17/300] d_loss:0.8259 g_loss: 1.4407 D(x):0.72 D(G(z)):0.29\n",
      "이폭 [18/300] d_loss:0.9310 g_loss: 1.3273 D(x):0.74 D(G(z)):0.36\n",
      "이폭 [19/300] d_loss:0.8682 g_loss: 1.5614 D(x):0.70 D(G(z)):0.30\n",
      "이폭 [20/300] d_loss:1.1359 g_loss: 1.2772 D(x):0.66 D(G(z)):0.35\n",
      "이폭 [21/300] d_loss:0.8574 g_loss: 1.6170 D(x):0.70 D(G(z)):0.28\n",
      "이폭 [22/300] d_loss:1.0210 g_loss: 1.4203 D(x):0.70 D(G(z)):0.34\n",
      "이폭 [23/300] d_loss:0.9268 g_loss: 1.6490 D(x):0.70 D(G(z)):0.27\n",
      "이폭 [24/300] d_loss:1.0637 g_loss: 1.0749 D(x):0.70 D(G(z)):0.39\n",
      "이폭 [25/300] d_loss:0.8747 g_loss: 1.3590 D(x):0.73 D(G(z)):0.32\n",
      "이폭 [26/300] d_loss:1.1346 g_loss: 1.1370 D(x):0.58 D(G(z)):0.36\n",
      "이폭 [27/300] d_loss:0.9745 g_loss: 1.2557 D(x):0.67 D(G(z)):0.33\n",
      "이폭 [28/300] d_loss:1.0997 g_loss: 1.0929 D(x):0.61 D(G(z)):0.40\n",
      "이폭 [29/300] d_loss:1.1185 g_loss: 1.0659 D(x):0.65 D(G(z)):0.37\n",
      "이폭 [30/300] d_loss:0.9931 g_loss: 1.2331 D(x):0.68 D(G(z)):0.36\n",
      "이폭 [31/300] d_loss:1.0575 g_loss: 1.1785 D(x):0.64 D(G(z)):0.37\n",
      "이폭 [32/300] d_loss:1.0904 g_loss: 1.0939 D(x):0.62 D(G(z)):0.38\n",
      "이폭 [33/300] d_loss:1.1757 g_loss: 1.3000 D(x):0.53 D(G(z)):0.31\n",
      "이폭 [34/300] d_loss:1.1384 g_loss: 1.3597 D(x):0.66 D(G(z)):0.37\n",
      "이폭 [35/300] d_loss:1.1994 g_loss: 1.3943 D(x):0.60 D(G(z)):0.34\n",
      "이폭 [36/300] d_loss:1.4124 g_loss: 0.9545 D(x):0.57 D(G(z)):0.47\n",
      "이폭 [37/300] d_loss:1.1150 g_loss: 1.1920 D(x):0.68 D(G(z)):0.38\n",
      "이폭 [38/300] d_loss:1.0930 g_loss: 1.3916 D(x):0.70 D(G(z)):0.38\n",
      "이폭 [39/300] d_loss:1.0008 g_loss: 1.3749 D(x):0.64 D(G(z)):0.33\n",
      "이폭 [40/300] d_loss:1.0593 g_loss: 1.2334 D(x):0.62 D(G(z)):0.35\n",
      "이폭 [41/300] d_loss:1.0683 g_loss: 1.1858 D(x):0.63 D(G(z)):0.37\n",
      "이폭 [42/300] d_loss:1.1555 g_loss: 1.0724 D(x):0.63 D(G(z)):0.42\n",
      "이폭 [43/300] d_loss:1.1918 g_loss: 1.2854 D(x):0.58 D(G(z)):0.35\n",
      "이폭 [44/300] d_loss:1.1139 g_loss: 1.0954 D(x):0.62 D(G(z)):0.38\n",
      "이폭 [45/300] d_loss:1.0895 g_loss: 1.1055 D(x):0.67 D(G(z)):0.41\n",
      "이폭 [46/300] d_loss:0.9662 g_loss: 1.2766 D(x):0.64 D(G(z)):0.32\n",
      "이폭 [47/300] d_loss:1.1798 g_loss: 1.0716 D(x):0.62 D(G(z)):0.41\n",
      "이폭 [48/300] d_loss:1.0952 g_loss: 1.2098 D(x):0.62 D(G(z)):0.35\n",
      "이폭 [49/300] d_loss:1.0428 g_loss: 1.3183 D(x):0.58 D(G(z)):0.28\n",
      "이폭 [50/300] d_loss:1.2285 g_loss: 0.9696 D(x):0.59 D(G(z)):0.41\n",
      "이폭 [51/300] d_loss:1.2987 g_loss: 1.0819 D(x):0.54 D(G(z)):0.37\n",
      "이폭 [52/300] d_loss:1.0142 g_loss: 1.1697 D(x):0.67 D(G(z)):0.37\n",
      "이폭 [53/300] d_loss:1.2572 g_loss: 1.2055 D(x):0.59 D(G(z)):0.39\n",
      "이폭 [54/300] d_loss:1.0118 g_loss: 1.2833 D(x):0.65 D(G(z)):0.35\n",
      "이폭 [55/300] d_loss:1.1341 g_loss: 1.1891 D(x):0.56 D(G(z)):0.33\n",
      "이폭 [56/300] d_loss:1.3242 g_loss: 0.9105 D(x):0.53 D(G(z)):0.43\n",
      "이폭 [57/300] d_loss:1.2187 g_loss: 0.9360 D(x):0.60 D(G(z)):0.44\n",
      "이폭 [58/300] d_loss:1.0808 g_loss: 1.3801 D(x):0.63 D(G(z)):0.31\n",
      "이폭 [59/300] d_loss:1.0211 g_loss: 1.2685 D(x):0.63 D(G(z)):0.33\n",
      "이폭 [60/300] d_loss:1.2918 g_loss: 1.0316 D(x):0.57 D(G(z)):0.42\n",
      "이폭 [61/300] d_loss:1.3629 g_loss: 1.1476 D(x):0.57 D(G(z)):0.39\n",
      "이폭 [62/300] d_loss:1.2328 g_loss: 1.2601 D(x):0.60 D(G(z)):0.38\n",
      "이폭 [63/300] d_loss:1.1985 g_loss: 0.9710 D(x):0.58 D(G(z)):0.40\n",
      "이폭 [64/300] d_loss:1.0480 g_loss: 1.0262 D(x):0.64 D(G(z)):0.38\n",
      "이폭 [65/300] d_loss:1.1053 g_loss: 1.0959 D(x):0.64 D(G(z)):0.38\n",
      "이폭 [66/300] d_loss:1.3011 g_loss: 1.0914 D(x):0.53 D(G(z)):0.38\n",
      "이폭 [67/300] d_loss:1.1783 g_loss: 0.9782 D(x):0.57 D(G(z)):0.41\n",
      "이폭 [68/300] d_loss:1.1560 g_loss: 0.9165 D(x):0.63 D(G(z)):0.42\n",
      "이폭 [69/300] d_loss:1.1493 g_loss: 1.1519 D(x):0.60 D(G(z)):0.40\n",
      "이폭 [70/300] d_loss:1.2935 g_loss: 1.1415 D(x):0.57 D(G(z)):0.39\n",
      "이폭 [71/300] d_loss:1.0074 g_loss: 1.2895 D(x):0.62 D(G(z)):0.31\n",
      "이폭 [72/300] d_loss:1.2768 g_loss: 0.9282 D(x):0.55 D(G(z)):0.45\n",
      "이폭 [73/300] d_loss:1.0387 g_loss: 0.9865 D(x):0.67 D(G(z)):0.40\n",
      "이폭 [74/300] d_loss:1.1771 g_loss: 1.0085 D(x):0.60 D(G(z)):0.42\n",
      "이폭 [75/300] d_loss:1.3148 g_loss: 1.0512 D(x):0.56 D(G(z)):0.43\n",
      "이폭 [76/300] d_loss:1.2353 g_loss: 0.9745 D(x):0.64 D(G(z)):0.44\n",
      "이폭 [77/300] d_loss:1.3213 g_loss: 1.2496 D(x):0.55 D(G(z)):0.34\n",
      "이폭 [78/300] d_loss:1.1755 g_loss: 1.1385 D(x):0.63 D(G(z)):0.40\n",
      "이폭 [79/300] d_loss:1.1488 g_loss: 1.2901 D(x):0.61 D(G(z)):0.37\n",
      "이폭 [80/300] d_loss:1.1588 g_loss: 0.9467 D(x):0.58 D(G(z)):0.40\n",
      "이폭 [81/300] d_loss:1.0451 g_loss: 0.9348 D(x):0.68 D(G(z)):0.43\n",
      "이폭 [82/300] d_loss:1.2137 g_loss: 1.1887 D(x):0.60 D(G(z)):0.42\n",
      "이폭 [83/300] d_loss:1.1762 g_loss: 0.9482 D(x):0.60 D(G(z)):0.41\n",
      "이폭 [84/300] d_loss:1.1017 g_loss: 1.2438 D(x):0.68 D(G(z)):0.39\n",
      "이폭 [85/300] d_loss:1.1873 g_loss: 1.2722 D(x):0.57 D(G(z)):0.36\n",
      "이폭 [86/300] d_loss:1.0551 g_loss: 1.1787 D(x):0.62 D(G(z)):0.36\n",
      "이폭 [87/300] d_loss:1.1393 g_loss: 1.1791 D(x):0.62 D(G(z)):0.39\n",
      "이폭 [88/300] d_loss:1.0691 g_loss: 0.9636 D(x):0.64 D(G(z)):0.42\n",
      "이폭 [89/300] d_loss:1.1543 g_loss: 1.0826 D(x):0.63 D(G(z)):0.42\n",
      "이폭 [90/300] d_loss:1.1486 g_loss: 0.9423 D(x):0.61 D(G(z)):0.41\n",
      "이폭 [91/300] d_loss:1.1213 g_loss: 1.2426 D(x):0.60 D(G(z)):0.35\n",
      "이폭 [92/300] d_loss:1.1796 g_loss: 0.9658 D(x):0.61 D(G(z)):0.41\n",
      "이폭 [93/300] d_loss:1.2991 g_loss: 1.0268 D(x):0.60 D(G(z)):0.45\n",
      "이폭 [94/300] d_loss:1.3485 g_loss: 0.9862 D(x):0.53 D(G(z)):0.43\n",
      "이폭 [95/300] d_loss:1.0495 g_loss: 1.0736 D(x):0.65 D(G(z)):0.37\n",
      "이폭 [96/300] d_loss:1.2465 g_loss: 1.0373 D(x):0.61 D(G(z)):0.44\n",
      "이폭 [97/300] d_loss:1.0936 g_loss: 1.1204 D(x):0.61 D(G(z)):0.36\n",
      "이폭 [98/300] d_loss:1.2104 g_loss: 1.3022 D(x):0.63 D(G(z)):0.40\n",
      "이폭 [99/300] d_loss:1.2033 g_loss: 1.0250 D(x):0.55 D(G(z)):0.39\n",
      "이폭 [100/300] d_loss:1.1716 g_loss: 1.0547 D(x):0.61 D(G(z)):0.41\n",
      "이폭 [101/300] d_loss:0.9547 g_loss: 1.2711 D(x):0.72 D(G(z)):0.36\n",
      "이폭 [102/300] d_loss:1.0665 g_loss: 1.0978 D(x):0.71 D(G(z)):0.42\n",
      "이폭 [103/300] d_loss:1.2542 g_loss: 0.9289 D(x):0.54 D(G(z)):0.42\n",
      "이폭 [104/300] d_loss:1.3643 g_loss: 0.8174 D(x):0.54 D(G(z)):0.47\n",
      "이폭 [105/300] d_loss:1.4676 g_loss: 0.9625 D(x):0.50 D(G(z)):0.42\n",
      "이폭 [106/300] d_loss:0.9359 g_loss: 1.3596 D(x):0.63 D(G(z)):0.28\n",
      "이폭 [107/300] d_loss:1.1302 g_loss: 1.2079 D(x):0.60 D(G(z)):0.35\n",
      "이폭 [108/300] d_loss:1.1908 g_loss: 0.9589 D(x):0.58 D(G(z)):0.41\n",
      "이폭 [109/300] d_loss:1.3257 g_loss: 1.0004 D(x):0.52 D(G(z)):0.41\n",
      "이폭 [110/300] d_loss:1.0463 g_loss: 1.2129 D(x):0.66 D(G(z)):0.37\n",
      "이폭 [111/300] d_loss:1.1327 g_loss: 0.9494 D(x):0.58 D(G(z)):0.41\n",
      "이폭 [112/300] d_loss:1.2885 g_loss: 1.1311 D(x):0.56 D(G(z)):0.40\n",
      "이폭 [113/300] d_loss:1.2372 g_loss: 1.0642 D(x):0.55 D(G(z)):0.38\n",
      "이폭 [114/300] d_loss:1.2145 g_loss: 1.2172 D(x):0.65 D(G(z)):0.39\n",
      "이폭 [115/300] d_loss:1.2667 g_loss: 0.9896 D(x):0.56 D(G(z)):0.42\n",
      "이폭 [116/300] d_loss:1.1935 g_loss: 1.2836 D(x):0.59 D(G(z)):0.34\n",
      "이폭 [117/300] d_loss:1.1458 g_loss: 0.9429 D(x):0.62 D(G(z)):0.41\n",
      "이폭 [118/300] d_loss:1.2906 g_loss: 0.8917 D(x):0.53 D(G(z)):0.42\n",
      "이폭 [119/300] d_loss:1.2096 g_loss: 0.9955 D(x):0.58 D(G(z)):0.42\n",
      "이폭 [120/300] d_loss:1.2840 g_loss: 1.0350 D(x):0.55 D(G(z)):0.41\n",
      "이폭 [121/300] d_loss:1.2093 g_loss: 1.0860 D(x):0.60 D(G(z)):0.43\n",
      "이폭 [122/300] d_loss:1.3304 g_loss: 0.8721 D(x):0.55 D(G(z)):0.46\n",
      "이폭 [123/300] d_loss:1.1173 g_loss: 1.1080 D(x):0.62 D(G(z)):0.40\n",
      "이폭 [124/300] d_loss:1.2063 g_loss: 0.9403 D(x):0.62 D(G(z)):0.43\n",
      "이폭 [125/300] d_loss:1.1513 g_loss: 1.0686 D(x):0.58 D(G(z)):0.38\n",
      "이폭 [126/300] d_loss:1.2035 g_loss: 0.9827 D(x):0.59 D(G(z)):0.42\n",
      "이폭 [127/300] d_loss:1.2975 g_loss: 0.9576 D(x):0.56 D(G(z)):0.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이폭 [128/300] d_loss:1.3620 g_loss: 0.7812 D(x):0.56 D(G(z)):0.48\n",
      "이폭 [129/300] d_loss:1.2398 g_loss: 0.9357 D(x):0.60 D(G(z)):0.43\n",
      "이폭 [130/300] d_loss:1.1394 g_loss: 1.0412 D(x):0.63 D(G(z)):0.41\n",
      "이폭 [131/300] d_loss:1.2373 g_loss: 1.2306 D(x):0.54 D(G(z)):0.35\n",
      "이폭 [132/300] d_loss:1.1669 g_loss: 1.0370 D(x):0.58 D(G(z)):0.39\n",
      "이폭 [133/300] d_loss:1.1910 g_loss: 0.9166 D(x):0.57 D(G(z)):0.42\n",
      "이폭 [134/300] d_loss:1.1920 g_loss: 1.0117 D(x):0.61 D(G(z)):0.42\n",
      "이폭 [135/300] d_loss:1.3474 g_loss: 1.0011 D(x):0.50 D(G(z)):0.41\n",
      "이폭 [136/300] d_loss:1.1307 g_loss: 1.0116 D(x):0.59 D(G(z)):0.39\n",
      "이폭 [137/300] d_loss:1.2815 g_loss: 1.2175 D(x):0.55 D(G(z)):0.36\n",
      "이폭 [138/300] d_loss:1.2454 g_loss: 0.9527 D(x):0.54 D(G(z)):0.41\n",
      "이폭 [139/300] d_loss:1.3799 g_loss: 0.8091 D(x):0.57 D(G(z)):0.48\n",
      "이폭 [140/300] d_loss:1.2009 g_loss: 0.9644 D(x):0.62 D(G(z)):0.44\n",
      "이폭 [141/300] d_loss:1.3053 g_loss: 0.8883 D(x):0.57 D(G(z)):0.45\n",
      "이폭 [142/300] d_loss:1.2064 g_loss: 1.0585 D(x):0.56 D(G(z)):0.40\n",
      "이폭 [143/300] d_loss:1.1026 g_loss: 1.4593 D(x):0.64 D(G(z)):0.34\n",
      "이폭 [144/300] d_loss:1.1273 g_loss: 1.0728 D(x):0.61 D(G(z)):0.39\n",
      "이폭 [145/300] d_loss:1.2820 g_loss: 1.0160 D(x):0.54 D(G(z)):0.42\n",
      "이폭 [146/300] d_loss:1.2312 g_loss: 1.0884 D(x):0.56 D(G(z)):0.40\n",
      "이폭 [147/300] d_loss:1.3240 g_loss: 0.9040 D(x):0.54 D(G(z)):0.44\n",
      "이폭 [148/300] d_loss:1.2988 g_loss: 0.8793 D(x):0.59 D(G(z)):0.46\n",
      "이폭 [149/300] d_loss:1.3368 g_loss: 1.1456 D(x):0.66 D(G(z)):0.46\n",
      "이폭 [150/300] d_loss:1.1751 g_loss: 1.0350 D(x):0.58 D(G(z)):0.40\n",
      "이폭 [151/300] d_loss:1.1731 g_loss: 0.9318 D(x):0.57 D(G(z)):0.40\n",
      "이폭 [152/300] d_loss:1.2054 g_loss: 1.1405 D(x):0.60 D(G(z)):0.41\n",
      "이폭 [153/300] d_loss:1.1563 g_loss: 1.2175 D(x):0.54 D(G(z)):0.33\n",
      "이폭 [154/300] d_loss:1.3443 g_loss: 1.0274 D(x):0.59 D(G(z)):0.46\n",
      "이폭 [155/300] d_loss:1.3282 g_loss: 1.0663 D(x):0.59 D(G(z)):0.44\n",
      "이폭 [156/300] d_loss:1.3361 g_loss: 1.0756 D(x):0.52 D(G(z)):0.39\n",
      "이폭 [157/300] d_loss:1.3016 g_loss: 1.0284 D(x):0.48 D(G(z)):0.37\n",
      "이폭 [158/300] d_loss:1.3559 g_loss: 0.8657 D(x):0.54 D(G(z)):0.46\n",
      "이폭 [159/300] d_loss:1.1675 g_loss: 1.1286 D(x):0.63 D(G(z)):0.42\n",
      "이폭 [160/300] d_loss:1.1668 g_loss: 1.2154 D(x):0.61 D(G(z)):0.38\n",
      "이폭 [161/300] d_loss:1.2889 g_loss: 0.8758 D(x):0.55 D(G(z)):0.45\n",
      "이폭 [162/300] d_loss:1.2761 g_loss: 1.0292 D(x):0.56 D(G(z)):0.42\n",
      "이폭 [163/300] d_loss:1.2516 g_loss: 1.2155 D(x):0.59 D(G(z)):0.36\n",
      "이폭 [164/300] d_loss:1.3767 g_loss: 0.9937 D(x):0.57 D(G(z)):0.45\n",
      "이폭 [165/300] d_loss:1.3275 g_loss: 0.8188 D(x):0.55 D(G(z)):0.48\n",
      "이폭 [166/300] d_loss:1.2805 g_loss: 0.8371 D(x):0.55 D(G(z)):0.46\n",
      "이폭 [167/300] d_loss:1.2054 g_loss: 0.9413 D(x):0.61 D(G(z)):0.44\n",
      "이폭 [168/300] d_loss:1.2555 g_loss: 0.8945 D(x):0.58 D(G(z)):0.45\n",
      "이폭 [169/300] d_loss:1.2405 g_loss: 1.0735 D(x):0.57 D(G(z)):0.41\n",
      "이폭 [170/300] d_loss:1.2674 g_loss: 1.0918 D(x):0.54 D(G(z)):0.39\n",
      "이폭 [171/300] d_loss:1.0863 g_loss: 0.9254 D(x):0.62 D(G(z)):0.42\n",
      "이폭 [172/300] d_loss:1.2497 g_loss: 0.9072 D(x):0.56 D(G(z)):0.43\n",
      "이폭 [173/300] d_loss:1.2296 g_loss: 0.9925 D(x):0.56 D(G(z)):0.42\n",
      "이폭 [174/300] d_loss:1.3043 g_loss: 0.9781 D(x):0.52 D(G(z)):0.42\n",
      "이폭 [175/300] d_loss:1.3366 g_loss: 0.8208 D(x):0.57 D(G(z)):0.47\n",
      "이폭 [176/300] d_loss:1.2589 g_loss: 0.9356 D(x):0.57 D(G(z)):0.44\n",
      "이폭 [177/300] d_loss:1.2456 g_loss: 0.8419 D(x):0.57 D(G(z)):0.45\n",
      "이폭 [178/300] d_loss:1.1183 g_loss: 1.0478 D(x):0.61 D(G(z)):0.40\n",
      "이폭 [179/300] d_loss:1.4340 g_loss: 1.1604 D(x):0.49 D(G(z)):0.38\n",
      "이폭 [180/300] d_loss:1.2013 g_loss: 1.0264 D(x):0.57 D(G(z)):0.40\n",
      "이폭 [181/300] d_loss:1.2996 g_loss: 1.1338 D(x):0.54 D(G(z)):0.40\n",
      "이폭 [182/300] d_loss:1.2315 g_loss: 0.8962 D(x):0.57 D(G(z)):0.44\n",
      "이폭 [183/300] d_loss:1.2548 g_loss: 0.9590 D(x):0.56 D(G(z)):0.42\n",
      "이폭 [184/300] d_loss:1.3809 g_loss: 0.8542 D(x):0.56 D(G(z)):0.47\n",
      "이폭 [185/300] d_loss:1.1275 g_loss: 0.9101 D(x):0.59 D(G(z)):0.41\n",
      "이폭 [186/300] d_loss:1.3004 g_loss: 0.8959 D(x):0.58 D(G(z)):0.46\n",
      "이폭 [187/300] d_loss:0.9944 g_loss: 1.0387 D(x):0.68 D(G(z)):0.39\n",
      "이폭 [188/300] d_loss:1.1944 g_loss: 0.9277 D(x):0.58 D(G(z)):0.43\n",
      "이폭 [189/300] d_loss:1.3710 g_loss: 1.1089 D(x):0.51 D(G(z)):0.39\n",
      "이폭 [190/300] d_loss:1.3759 g_loss: 1.0083 D(x):0.56 D(G(z)):0.44\n",
      "이폭 [191/300] d_loss:1.2217 g_loss: 0.9117 D(x):0.57 D(G(z)):0.43\n",
      "이폭 [192/300] d_loss:1.1853 g_loss: 1.0484 D(x):0.60 D(G(z)):0.41\n",
      "이폭 [193/300] d_loss:1.2400 g_loss: 0.9419 D(x):0.53 D(G(z)):0.41\n",
      "이폭 [194/300] d_loss:1.3326 g_loss: 0.8850 D(x):0.53 D(G(z)):0.43\n",
      "이폭 [195/300] d_loss:1.0712 g_loss: 0.9524 D(x):0.64 D(G(z)):0.41\n",
      "이폭 [196/300] d_loss:1.3029 g_loss: 0.9919 D(x):0.54 D(G(z)):0.41\n",
      "이폭 [197/300] d_loss:1.3373 g_loss: 1.0349 D(x):0.54 D(G(z)):0.41\n",
      "이폭 [198/300] d_loss:1.3663 g_loss: 0.7199 D(x):0.59 D(G(z)):0.52\n",
      "이폭 [199/300] d_loss:1.2309 g_loss: 0.9953 D(x):0.58 D(G(z)):0.40\n",
      "이폭 [200/300] d_loss:1.3403 g_loss: 1.0189 D(x):0.51 D(G(z)):0.41\n",
      "이폭 [201/300] d_loss:1.2036 g_loss: 0.9421 D(x):0.60 D(G(z)):0.44\n",
      "이폭 [202/300] d_loss:1.3424 g_loss: 0.8681 D(x):0.55 D(G(z)):0.46\n",
      "이폭 [203/300] d_loss:1.2065 g_loss: 0.8052 D(x):0.61 D(G(z)):0.47\n",
      "이폭 [204/300] d_loss:1.1212 g_loss: 0.9913 D(x):0.61 D(G(z)):0.42\n",
      "이폭 [205/300] d_loss:1.2166 g_loss: 0.9751 D(x):0.54 D(G(z)):0.40\n",
      "이폭 [206/300] d_loss:1.2565 g_loss: 0.9664 D(x):0.55 D(G(z)):0.40\n",
      "이폭 [207/300] d_loss:1.3733 g_loss: 0.8029 D(x):0.56 D(G(z)):0.49\n",
      "이폭 [208/300] d_loss:1.3579 g_loss: 0.7690 D(x):0.58 D(G(z)):0.50\n",
      "이폭 [209/300] d_loss:1.2288 g_loss: 1.1779 D(x):0.65 D(G(z)):0.41\n",
      "이폭 [210/300] d_loss:1.1998 g_loss: 0.8837 D(x):0.59 D(G(z)):0.43\n",
      "이폭 [211/300] d_loss:1.1267 g_loss: 1.1897 D(x):0.61 D(G(z)):0.38\n",
      "이폭 [212/300] d_loss:1.2761 g_loss: 0.8956 D(x):0.59 D(G(z)):0.45\n",
      "이폭 [213/300] d_loss:1.2316 g_loss: 1.1059 D(x):0.62 D(G(z)):0.40\n",
      "이폭 [214/300] d_loss:1.3094 g_loss: 0.9476 D(x):0.59 D(G(z)):0.47\n",
      "이폭 [215/300] d_loss:1.3774 g_loss: 1.0123 D(x):0.55 D(G(z)):0.44\n",
      "이폭 [216/300] d_loss:1.3337 g_loss: 0.9311 D(x):0.55 D(G(z)):0.45\n",
      "이폭 [217/300] d_loss:1.2180 g_loss: 0.9638 D(x):0.58 D(G(z)):0.42\n",
      "이폭 [218/300] d_loss:1.3372 g_loss: 0.7805 D(x):0.56 D(G(z)):0.49\n",
      "이폭 [219/300] d_loss:1.0714 g_loss: 1.1988 D(x):0.65 D(G(z)):0.37\n",
      "이폭 [220/300] d_loss:1.2390 g_loss: 1.0315 D(x):0.57 D(G(z)):0.42\n",
      "이폭 [221/300] d_loss:1.2439 g_loss: 0.8950 D(x):0.56 D(G(z)):0.43\n",
      "이폭 [222/300] d_loss:1.2725 g_loss: 0.9385 D(x):0.56 D(G(z)):0.43\n",
      "이폭 [223/300] d_loss:1.3220 g_loss: 0.8305 D(x):0.56 D(G(z)):0.47\n",
      "이폭 [224/300] d_loss:1.3008 g_loss: 1.0509 D(x):0.57 D(G(z)):0.44\n",
      "이폭 [225/300] d_loss:1.2621 g_loss: 0.9978 D(x):0.59 D(G(z)):0.44\n",
      "이폭 [226/300] d_loss:1.2543 g_loss: 0.9071 D(x):0.59 D(G(z)):0.44\n",
      "이폭 [227/300] d_loss:1.3323 g_loss: 0.9226 D(x):0.55 D(G(z)):0.43\n",
      "이폭 [228/300] d_loss:1.2664 g_loss: 1.1111 D(x):0.53 D(G(z)):0.38\n",
      "이폭 [229/300] d_loss:1.3196 g_loss: 0.7934 D(x):0.56 D(G(z)):0.48\n",
      "이폭 [230/300] d_loss:1.2061 g_loss: 1.0242 D(x):0.59 D(G(z)):0.42\n",
      "이폭 [231/300] d_loss:1.1554 g_loss: 1.0601 D(x):0.60 D(G(z)):0.39\n",
      "이폭 [232/300] d_loss:1.2839 g_loss: 1.0139 D(x):0.55 D(G(z)):0.40\n",
      "이폭 [233/300] d_loss:1.2303 g_loss: 0.9026 D(x):0.60 D(G(z)):0.45\n",
      "이폭 [234/300] d_loss:1.3240 g_loss: 1.0532 D(x):0.55 D(G(z)):0.42\n",
      "이폭 [235/300] d_loss:1.2080 g_loss: 0.8544 D(x):0.59 D(G(z)):0.42\n",
      "이폭 [236/300] d_loss:1.1367 g_loss: 1.1555 D(x):0.65 D(G(z)):0.40\n",
      "이폭 [237/300] d_loss:1.2425 g_loss: 0.8904 D(x):0.57 D(G(z)):0.45\n",
      "이폭 [238/300] d_loss:1.3378 g_loss: 1.0897 D(x):0.56 D(G(z)):0.40\n",
      "이폭 [239/300] d_loss:1.1115 g_loss: 0.9884 D(x):0.62 D(G(z)):0.41\n",
      "이폭 [240/300] d_loss:1.1836 g_loss: 0.8214 D(x):0.59 D(G(z)):0.45\n",
      "이폭 [241/300] d_loss:1.2102 g_loss: 0.9176 D(x):0.63 D(G(z)):0.44\n",
      "이폭 [242/300] d_loss:1.2689 g_loss: 1.0106 D(x):0.55 D(G(z)):0.40\n",
      "이폭 [243/300] d_loss:1.3724 g_loss: 0.7982 D(x):0.55 D(G(z)):0.48\n",
      "이폭 [244/300] d_loss:1.2814 g_loss: 0.8025 D(x):0.58 D(G(z)):0.48\n",
      "이폭 [245/300] d_loss:1.2556 g_loss: 0.8610 D(x):0.56 D(G(z)):0.45\n",
      "이폭 [246/300] d_loss:1.1237 g_loss: 1.0289 D(x):0.59 D(G(z)):0.38\n",
      "이폭 [247/300] d_loss:1.3713 g_loss: 0.8751 D(x):0.59 D(G(z)):0.49\n",
      "이폭 [248/300] d_loss:1.3040 g_loss: 0.9644 D(x):0.55 D(G(z)):0.44\n",
      "이폭 [249/300] d_loss:1.0512 g_loss: 1.0108 D(x):0.67 D(G(z)):0.40\n",
      "이폭 [250/300] d_loss:1.1721 g_loss: 1.0586 D(x):0.58 D(G(z)):0.39\n",
      "이폭 [251/300] d_loss:1.3488 g_loss: 0.8600 D(x):0.55 D(G(z)):0.47\n",
      "이폭 [252/300] d_loss:1.3148 g_loss: 1.0276 D(x):0.54 D(G(z)):0.43\n",
      "이폭 [253/300] d_loss:1.5211 g_loss: 0.7070 D(x):0.54 D(G(z)):0.52\n",
      "이폭 [254/300] d_loss:1.2984 g_loss: 1.1691 D(x):0.57 D(G(z)):0.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이폭 [255/300] d_loss:1.2203 g_loss: 0.9086 D(x):0.59 D(G(z)):0.43\n",
      "이폭 [256/300] d_loss:1.2320 g_loss: 1.0966 D(x):0.56 D(G(z)):0.40\n",
      "이폭 [257/300] d_loss:1.3268 g_loss: 0.9774 D(x):0.53 D(G(z)):0.42\n",
      "이폭 [258/300] d_loss:1.2899 g_loss: 1.0394 D(x):0.54 D(G(z)):0.42\n",
      "이폭 [259/300] d_loss:1.3372 g_loss: 0.7894 D(x):0.52 D(G(z)):0.46\n",
      "이폭 [260/300] d_loss:1.4328 g_loss: 0.8044 D(x):0.53 D(G(z)):0.47\n",
      "이폭 [261/300] d_loss:1.2954 g_loss: 0.9023 D(x):0.54 D(G(z)):0.42\n",
      "이폭 [262/300] d_loss:1.2584 g_loss: 0.9658 D(x):0.54 D(G(z)):0.40\n",
      "이폭 [263/300] d_loss:1.2811 g_loss: 0.8787 D(x):0.58 D(G(z)):0.47\n",
      "이폭 [264/300] d_loss:1.3819 g_loss: 0.9128 D(x):0.49 D(G(z)):0.43\n",
      "이폭 [265/300] d_loss:1.3775 g_loss: 0.7944 D(x):0.55 D(G(z)):0.49\n",
      "이폭 [266/300] d_loss:1.3488 g_loss: 0.8240 D(x):0.56 D(G(z)):0.48\n",
      "이폭 [267/300] d_loss:1.3836 g_loss: 0.9073 D(x):0.51 D(G(z)):0.44\n",
      "이폭 [268/300] d_loss:1.2127 g_loss: 1.0495 D(x):0.61 D(G(z)):0.40\n",
      "이폭 [269/300] d_loss:1.2328 g_loss: 0.9838 D(x):0.55 D(G(z)):0.41\n",
      "이폭 [270/300] d_loss:1.0695 g_loss: 1.0842 D(x):0.68 D(G(z)):0.42\n",
      "이폭 [271/300] d_loss:1.1232 g_loss: 1.0846 D(x):0.60 D(G(z)):0.40\n",
      "이폭 [272/300] d_loss:1.2631 g_loss: 0.8252 D(x):0.60 D(G(z)):0.46\n",
      "이폭 [273/300] d_loss:1.2599 g_loss: 0.8605 D(x):0.57 D(G(z)):0.45\n",
      "이폭 [274/300] d_loss:1.3252 g_loss: 0.8987 D(x):0.59 D(G(z)):0.48\n",
      "이폭 [275/300] d_loss:1.3041 g_loss: 0.9672 D(x):0.57 D(G(z)):0.42\n",
      "이폭 [276/300] d_loss:1.1820 g_loss: 0.8813 D(x):0.62 D(G(z)):0.44\n",
      "이폭 [277/300] d_loss:1.2781 g_loss: 0.8414 D(x):0.55 D(G(z)):0.45\n",
      "이폭 [278/300] d_loss:1.2187 g_loss: 1.0004 D(x):0.55 D(G(z)):0.39\n",
      "이폭 [279/300] d_loss:1.3091 g_loss: 0.8133 D(x):0.56 D(G(z)):0.47\n",
      "이폭 [280/300] d_loss:1.2176 g_loss: 1.0146 D(x):0.60 D(G(z)):0.39\n",
      "이폭 [281/300] d_loss:1.4756 g_loss: 0.8778 D(x):0.55 D(G(z)):0.45\n",
      "이폭 [282/300] d_loss:1.2602 g_loss: 0.8718 D(x):0.57 D(G(z)):0.44\n",
      "이폭 [283/300] d_loss:1.2841 g_loss: 0.8523 D(x):0.56 D(G(z)):0.44\n",
      "이폭 [284/300] d_loss:1.3044 g_loss: 0.8837 D(x):0.57 D(G(z)):0.47\n",
      "이폭 [285/300] d_loss:1.3578 g_loss: 0.9594 D(x):0.52 D(G(z)):0.43\n",
      "이폭 [286/300] d_loss:1.3274 g_loss: 0.9296 D(x):0.53 D(G(z)):0.43\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(BATCH_SIZE, -1).to(DEVICE)\n",
    "        \n",
    "        # '진짜'와 '가짜' 레이블 생성\n",
    "        real_labels = torch.ones(BATCH_SIZE, 1).to(DEVICE)\n",
    "        fake_labels = torch.zeros(BATCH_SIZE, 1).to(DEVICE)\n",
    "\n",
    "        # 판별자가 진짜 이미지를 진짜로 인식하는 오차를 계산 (데이터셋 레이블 입력)\n",
    "        outputs = D(images, labels)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "        \n",
    "        # 무작위 텐서와 무작위 레이블을 생성자에 입력해 가짜 이미지 생성\n",
    "        z = torch.randn(BATCH_SIZE, 100).to(DEVICE)\n",
    "        g_label = torch.randint(0, 10, (BATCH_SIZE,)).to(DEVICE)\n",
    "        fake_images= G(z, g_label)\n",
    "        \n",
    "        # 판별자가 가짜 이미지를 가짜로 인식하는 오차를 계산\n",
    "        outputs = D(fake_images, g_label)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        # 진짜와 가짜 이미지를 갖고 낸 오차를 더해서 판별자의 오차를 계산\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        \n",
    "        # 역전파 알고리즘으로 판별자 모델의 학습을 진행\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # 생성자가 판별자를 속였는지에 대한 오차를 계산 (무작위 레이블 입력)\n",
    "        fake_images = G(z, g_label)\n",
    "        outputs = D(fake_images, g_label)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        \n",
    "        # 역전파 알고리즘으로 생성자 모델의 학습을 진행\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "    print('이폭 [{}/{}] d_loss:{:.4f} g_loss: {:.4f} D(x):{:.2f} D(G(z)):{:.2f}' \n",
    "          .format(epoch, EPOCHS, d_loss.item(), g_loss.item(), \n",
    "                  real_score.mean().item(), fake_score.mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    label = torch.tensor([4])\n",
    "    class_label = one_hot_embedding(label, 10).to(DEVICE)\n",
    "    z = torch.randn(1, 64).to(DEVICE)\n",
    "    generator_input = torch.cat([z, class_label], 1)\n",
    "    fake_images= G(generator_input)\n",
    "    fake_images = np.reshape(fake_images.cpu().data.numpy()[0],(28, 28))\n",
    "    plt.imshow(fake_images, cmap = 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자가 만든 이미지 시각화하기\n",
    "z = torch.randn(BATCH_SIZE, 64).to(DEVICE)\n",
    "g_label = torch.randint(0, 10, (BATCH_SIZE, 10), dtype=torch.float).to(DEVICE)\n",
    "g_input = torch.cat([z, g_label], 1)\n",
    "fake_images = G(g_input)\n",
    "for i in range(64):\n",
    "    fake_images_img = np.reshape(fake_images.data.cpu().numpy()[i],(28, 28))\n",
    "    plt.imshow(fake_images_img, cmap = 'gray')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
