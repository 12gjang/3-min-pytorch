{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq 기계 번역\n",
    "\n",
    "이번 프로젝트에선 임의로 Seq2Seq 모델을 아주 간단화 시켰습니다.\n",
    "한 언어로 된 문장을 다른 언어로 된 문장으로 번역하는 덩치가 큰 모델이 아닌\n",
    "영어 알파벳 문자열(\"hello\")을 스페인어 알파벳 문자열(\"hola\")로 번역하는 Mini Seq2Seq 모델을 같이 구현해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello ->  [104, 101, 108, 108, 111]\n",
      "hola  ->  [104, 111, 108, 97]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 256  # 총 아스키 코드 개수\n",
    "x_ = list(map(ord, \"hello\"))  # 아스키 코드 리스트로 변환\n",
    "y_ = list(map(ord, \"hola\"))   # 아스키 코드 리스트로 변환\n",
    "print(\"hello -> \", x_)\n",
    "print(\"hola  -> \", y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.LongTensor(x_)\n",
    "y = torch.LongTensor(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.n_layers = 1\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.encoder = nn.GRU(hidden_size, hidden_size)\n",
    "        self.decoder = nn.GRU(hidden_size, hidden_size)\n",
    "        self.project = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # 인코더에 들어갈 입력\n",
    "        initial_state = self._init_state()\n",
    "        embedding = self.embedding(inputs).unsqueeze(1)\n",
    "        # embedding = [seq_len, batch_size, embedding_size]\n",
    "        \n",
    "        # 인코더 (Encoder)\n",
    "        encoder_output, encoder_state = self.encoder(embedding, initial_state)\n",
    "        # encoder_output = [seq_len, batch_size, hidden_size]\n",
    "        # encoder_state  = [n_layers, seq_len, hidden_size]\n",
    "\n",
    "        # 디코더에 들어갈 입력\n",
    "        decoder_state = encoder_state\n",
    "        decoder_input = torch.LongTensor([[0]])\n",
    "        \n",
    "        # 디코더 (Decoder)\n",
    "        outputs = []\n",
    "        \n",
    "        # 티쳐 포싱 (Teacher Forcing)\n",
    "        use_teacher_forcing = True# if random.random() < 0.5 else False\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            for i in range(targets.size()[0]):\n",
    "                decoder_input = self.embedding(decoder_input)\n",
    "                decoder_output, decoder_state = self.decoder(decoder_input, decoder_state)\n",
    "                projection = self.project(decoder_output)#.unsqueeze(0))\n",
    "                outputs.append(projection)\n",
    "                decoder_input = torch.LongTensor([[targets[i]]])\n",
    "        else:\n",
    "            for i in range(targets.size()[0]): \n",
    "                decoder_input = self.embedding(decoder_input)\n",
    "#                 decoder_input = torch.cat((decoder_input, encoder_state), 2)\n",
    "                decoder_output, decoder_state = self.decoder(decoder_input, decoder_state)\n",
    "\n",
    "                # 디코더의 출력값으로 다음 글자 예측하기\n",
    "                projection = self.project(decoder_output.view(1, -1))  # batch x vocab_size\n",
    "                prediction = F.softmax(projection, dim=1)  # batch x vocab_size\n",
    "                outputs.append(prediction)\n",
    "\n",
    "                # 디코더 입력 갱신\n",
    "                _, top_i = prediction.data.topk(1)  # 1 x 1\n",
    "                decoder_input = top_i\n",
    "            \n",
    "\n",
    "        outputs = torch.stack(outputs).squeeze()\n",
    "        return outputs\n",
    "    \n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return weight.new(self.n_layers, batch_size, self.hidden_size).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (embedding): Embedding(256, 16)\n",
      "  (encoder): GRU(16, 16)\n",
      "  (decoder): GRU(16, 16)\n",
      "  (project): Linear(in_features=16, out_features=256, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "seq2seq = Seq2Seq(vocab_size, 16)\n",
    "print(seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(seq2seq.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 반복:0 오차: 5.539267539978027\n",
      "['Å', 'ò', 'ò', '\\x12']\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:100 오차: 1.8475919961929321\n",
      "['h', 'o', 'l', 'a']\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:200 오차: 0.6000521779060364\n",
      "['h', 'o', 'l', 'a']\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:300 오차: 0.28734850883483887\n",
      "['h', 'o', 'l', 'a']\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:400 오차: 0.17892339825630188\n",
      "['h', 'o', 'l', 'a']\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:500 오차: 0.12511952221393585\n",
      "['h', 'o', 'l', 'a']\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:600 오차: 0.09342227131128311\n",
      "['h', 'o', 'l', 'a']\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:700 오차: 0.07278146594762802\n",
      "['h', 'o', 'l', 'a']\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:800 오차: 0.05734049528837204\n",
      "['h', 'o', 'l', 'a']\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:900 오차: 0.04412749409675598\n",
      "['h', 'o', 'l', 'a']\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:1000 오차: 0.03519321233034134\n",
      "['h', 'o', 'l', 'a']\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:1100 오차: 0.028974980115890503\n",
      "['h', 'o', 'l', 'a']\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:1200 오차: 0.02441542223095894\n",
      "['h', 'o', 'l', 'a']\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:1300 오차: 0.020931990817189217\n",
      "['h', 'o', 'l', 'a']\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:1400 오차: 0.0181867778301239\n",
      "['h', 'o', 'l', 'a']\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:1500 오차: 0.015970785170793533\n",
      "['h', 'o', 'l', 'a']\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:1600 오차: 0.014147497713565826\n",
      "['h', 'o', 'l', 'a']\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:1700 오차: 0.012623758986592293\n",
      "['h', 'o', 'l', 'a']\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:1800 오차: 0.01133372075855732\n",
      "['h', 'o', 'l', 'a']\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:1900 오차: 0.010229488834738731\n",
      "['h', 'o', 'l', 'a']\n",
      "['h', 'o', 'l', 'a']\n"
     ]
    }
   ],
   "source": [
    "log = []\n",
    "for i in range(2000):\n",
    "    prediction = seq2seq(x, y)\n",
    "    loss = criterion(prediction, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_val = loss.data\n",
    "    log.append(loss_val)\n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n 반복:%d 오차: %s\" % (i, loss_val.item()))\n",
    "        _, top1 = prediction.data.topk(1, 1)\n",
    "        print([chr(c) for c in top1.squeeze().numpy().tolist()])\n",
    "        print([chr(c) for c in y.squeeze().numpy().tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhPj/Synnh3fdSfQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121110be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(log)\n",
    "plt.ylabel('cross entropy loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
