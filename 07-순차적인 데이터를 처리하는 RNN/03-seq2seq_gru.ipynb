{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq 기계 번역\n",
    "\n",
    "이번 프로젝트에선 임의로 Seq2Seq 모델을 아주 간단화 시켰습니다.\n",
    "한 언어로 된 문장을 다른 언어로 된 문장으로 번역하는 덩치가 큰 모델이 아닌\n",
    "영어 알파벳 문자열(\"hello\")을 스페인어 알파벳 문자열(\"hola\")로 번역하는 Mini Seq2Seq 모델을 같이 구현해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello ->  [104, 101, 108, 108, 111]\n",
      "hola  ->  [104, 111, 108, 97]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 256  # 총 아스키 코드 개수\n",
    "x_ = list(map(ord, \"hello\"))  # 아스키 코드 리스트로 변환\n",
    "y_ = list(map(ord, \"hola\"))   # 아스키 코드 리스트로 변환\n",
    "print(\"hello -> \", x_)\n",
    "print(\"hola  -> \", y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.LongTensor(x_)\n",
    "y = torch.LongTensor(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "미니 GRU 모델.\n",
    "'''\n",
    "class Seq2Seq_GRU(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(Seq2Seq_GRU, self).__init__()\n",
    "\n",
    "        self.n_layers = 1\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.encoder = nn.GRU(hidden_size, hidden_size)\n",
    "        self.decoder = nn.GRU(hidden_size * 2, hidden_size)\n",
    "        self.project = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Encoder inputs and states\n",
    "        initial_state = self._init_state()\n",
    "        embedding = self.embedding(inputs).unsqueeze(1)\n",
    "        encoder_output, encoder_state = self.encoder(embedding, initial_state)\n",
    "        outputs = []\n",
    "\n",
    "        decoder_state = encoder_state\n",
    "        for i in range(targets.size()[0]): \n",
    "            decoder_input = self.embedding(targets)[i].view(1,-1, self.hidden_size)\n",
    "            decoder_input = th.cat((decoder_input, encoder_state), 2)\n",
    "            decoder_output, decoder_state = self.decoder(decoder_input, decoder_state)\n",
    "            projection = self.project(decoder_output)#.unsqueeze(0))\n",
    "            outputs.append(projection)\n",
    "            \n",
    "            #_, top_i = prediction.data.topk(1)\n",
    "            \n",
    "        outputs = th.stack(outputs, 1).squeeze()\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return Variable(weight.new(self.n_layers, batch_size, self.hidden_size).zero_()) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq_GRU(vocab_size, 16)\n",
    "pred = model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_.append(3)\n",
    "y_label = Variable(th.LongTensor(y_[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "tensor([111, 108,  97,   3])\n"
     ]
    }
   ],
   "source": [
    "print(y_label.shape)\n",
    "print(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 5.712370872497559\n",
      "] , , å \n",
      "100 loss: 2.0981945991516113\n",
      "h o l a \n",
      "200 loss: 0.6704353094100952\n",
      "h o l a \n",
      "300 loss: 0.3248082399368286\n",
      "h o l a \n",
      "400 loss: 0.18652379512786865\n",
      "h o l a \n",
      "500 loss: 0.11785173416137695\n",
      "h o l a \n",
      "600 loss: 0.08392083644866943\n",
      "h o l a \n",
      "700 loss: 0.06378734111785889\n",
      "h o l a \n",
      "800 loss: 0.05056416988372803\n",
      "h o l a \n",
      "900 loss: 0.041283249855041504\n",
      "h o l a \n",
      "1000 loss: 0.0344545841217041\n",
      "h o l a \n",
      "1100 loss: 0.02924966812133789\n",
      "h o l a \n",
      "1200 loss: 0.025171399116516113\n",
      "h o l a \n",
      "1300 loss: 0.021904587745666504\n",
      "h o l a \n",
      "1400 loss: 0.01923954486846924\n",
      "h o l a \n",
      "1500 loss: 0.01703178882598877\n",
      "h o l a \n",
      "1600 loss: 0.015179157257080078\n",
      "h o l a \n",
      "1700 loss: 0.013607501983642578\n",
      "h o l a \n",
      "1800 loss: 0.012260913848876953\n",
      "h o l a \n",
      "1900 loss: 0.011096715927124023\n",
      "h o l a \n",
      "2000 loss: 0.010083198547363281\n",
      "h o l a \n",
      "2100 loss: 0.009195327758789062\n",
      "h o l a \n",
      "2200 loss: 0.008411884307861328\n",
      "h o l a \n",
      "2300 loss: 0.007717609405517578\n",
      "h o l a \n",
      "2400 loss: 0.0070989131927490234\n",
      "h o l a \n",
      "2500 loss: 0.006545066833496094\n",
      "h o l a \n",
      "2600 loss: 0.006047487258911133\n",
      "h o l a \n",
      "2700 loss: 0.005598545074462891\n",
      "h o l a \n",
      "2800 loss: 0.00519251823425293\n",
      "h o l a \n",
      "2900 loss: 0.0048236846923828125\n",
      "h o l a \n",
      "3000 loss: 0.0044879913330078125\n",
      "h o l a \n",
      "3100 loss: 0.004181623458862305\n",
      "h o l a \n",
      "3200 loss: 0.003900766372680664\n",
      "h o l a \n",
      "3300 loss: 0.0036437511444091797\n",
      "h o l a \n",
      "3400 loss: 0.003407001495361328\n",
      "h o l a \n",
      "3500 loss: 0.0031890869140625\n",
      "h o l a \n",
      "3600 loss: 0.0029883384704589844\n",
      "h o l a \n",
      "3700 loss: 0.0028023719787597656\n",
      "h o l a \n",
      "3800 loss: 0.002629995346069336\n",
      "h o l a \n",
      "3900 loss: 0.0024704933166503906\n",
      "h o l a \n",
      "4000 loss: 0.0023224353790283203\n",
      "h o l a \n",
      "4100 loss: 0.0021843910217285156\n",
      "h o l a \n",
      "4200 loss: 0.002056121826171875\n",
      "h o l a \n",
      "4300 loss: 0.0019364356994628906\n",
      "h o l a \n",
      "4400 loss: 0.001825094223022461\n",
      "h o l a \n",
      "4500 loss: 0.001720428466796875\n",
      "h o l a \n",
      "4600 loss: 0.0016231536865234375\n",
      "h o l a \n",
      "4700 loss: 0.0015320777893066406\n",
      "h o l a \n",
      "4800 loss: 0.0014462471008300781\n",
      "h o l a \n",
      "4900 loss: 0.0013661384582519531\n",
      "h o l a \n",
      "5000 loss: 0.001291036605834961\n",
      "h o l a \n",
      "5100 loss: 0.0012202262878417969\n",
      "h o l a \n",
      "5200 loss: 0.001154184341430664\n",
      "h o l a \n",
      "5300 loss: 0.0010917186737060547\n",
      "h o l a \n",
      "5400 loss: 0.0010328292846679688\n",
      "h o l a \n",
      "5500 loss: 0.0009777545928955078\n",
      "h o l a \n",
      "5600 loss: 0.0009255409240722656\n",
      "h o l a \n",
      "5700 loss: 0.0008764266967773438\n",
      "h o l a \n",
      "5800 loss: 0.0008301734924316406\n",
      "h o l a \n",
      "5900 loss: 0.0007865428924560547\n",
      "h o l a \n",
      "6000 loss: 0.0007452964782714844\n",
      "h o l a \n",
      "6100 loss: 0.0007061958312988281\n",
      "h o l a \n",
      "6200 loss: 0.0006697177886962891\n",
      "h o l a \n",
      "6300 loss: 0.0006353855133056641\n",
      "h o l a \n",
      "6400 loss: 0.0006022453308105469\n",
      "h o l a \n",
      "6500 loss: 0.0005714893341064453\n",
      "h o l a \n",
      "6600 loss: 0.0005421638488769531\n",
      "h o l a \n",
      "6700 loss: 0.0005142688751220703\n",
      "h o l a \n",
      "6800 loss: 0.00048828125\n",
      "h o l a \n",
      "6900 loss: 0.0004630088806152344\n",
      "h o l a \n",
      "7000 loss: 0.00043964385986328125\n",
      "h o l a \n",
      "7100 loss: 0.00041747093200683594\n",
      "h o l a \n",
      "7200 loss: 0.00039649009704589844\n",
      "h o l a \n",
      "7300 loss: 0.0003762245178222656\n",
      "h o l a \n",
      "7400 loss: 0.0003573894500732422\n",
      "h o l a \n",
      "7500 loss: 0.000339508056640625\n",
      "h o l a \n",
      "7600 loss: 0.0003223419189453125\n",
      "h o l a \n",
      "7700 loss: 0.0003063678741455078\n",
      "h o l a \n",
      "7800 loss: 0.0002911090850830078\n",
      "h o l a \n",
      "7900 loss: 0.00027632713317871094\n",
      "h o l a \n",
      "8000 loss: 0.0002624988555908203\n",
      "h o l a \n",
      "8100 loss: 0.00024962425231933594\n",
      "h o l a \n",
      "8200 loss: 0.00023746490478515625\n",
      "h o l a \n",
      "8300 loss: 0.000225067138671875\n",
      "h o l a \n",
      "8400 loss: 0.0002143383026123047\n",
      "h o l a \n",
      "8500 loss: 0.00020360946655273438\n",
      "h o l a \n",
      "8600 loss: 0.00019359588623046875\n",
      "h o l a \n",
      "8700 loss: 0.0001838207244873047\n",
      "h o l a \n",
      "8800 loss: 0.0001747608184814453\n",
      "h o l a \n",
      "8900 loss: 0.00016617774963378906\n",
      "h o l a \n",
      "9000 loss: 0.00015807151794433594\n",
      "h o l a \n",
      "9100 loss: 0.0001499652862548828\n",
      "h o l a \n",
      "9200 loss: 0.00014281272888183594\n",
      "h o l a \n",
      "9300 loss: 0.00013589859008789062\n",
      "h o l a \n",
      "9400 loss: 0.00012874603271484375\n",
      "h o l a \n",
      "9500 loss: 0.00012254714965820312\n",
      "h o l a \n",
      "9600 loss: 0.00011658668518066406\n",
      "h o l a \n",
      "9700 loss: 0.00011086463928222656\n",
      "h o l a \n",
      "9800 loss: 0.00010514259338378906\n",
      "h o l a \n",
      "9900 loss: 0.00010013580322265625\n",
      "h o l a \n"
     ]
    }
   ],
   "source": [
    "log = []\n",
    "for i in range(10000):\n",
    "    prediction = model(x, y)\n",
    "    loss = criterion(prediction, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_val = loss.data\n",
    "    log.append(loss_val)\n",
    "    if i % 100 == 0:\n",
    "        print(\"%d loss: %s\" % (i, loss_val.item()))\n",
    "        _, top1 = prediction.data.topk(1, 1)\n",
    "        for c in top1.squeeze().numpy().tolist():\n",
    "            print(chr(c), end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(log)\n",
    "plt.xlim(0,150)\n",
    "plt.ylim(0,15)\n",
    "plt.ylabel('cross entropy loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
