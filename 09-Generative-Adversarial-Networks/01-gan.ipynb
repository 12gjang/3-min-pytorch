{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.1 GAN으로 새로운 패션아이템 생성하기\n",
    "*GAN을 이용하여 새로운 패션 아이템을 만들어봅니다*\n",
    "\n",
    "GAN을 설명할때 항상 나오는 명언이 있습니다.\n",
    "바로 양자 역학에 대한 공으로 노벨 물리학상을 받은\n",
    "리처드 파인만(Richard Feynman) 교수의\n",
    "\"내가 만들어낼 수 없다면 이해하지 못한 것이다\"\n",
    "(What I cannot create, I do not understand)\n",
    "라는 문장입니다.\n",
    "빈 종이가 주어졌을때 처음부터 끝까지 *자신만의\n",
    "자세한 설명*을 할 수 있어야 진정한 '이해'에\n",
    "도달한다는 취지에서 말을 한 것이라 생각됩니다.\n",
    "비슷한 맥락으로 단순히 고양이와 강아지를 구분하는 것과\n",
    "고양이와 강아지를 그릴 수 있는 것은 이해의 정도에\n",
    "큰 차이가 있다고 할 수 있습니다.\n",
    "우리가 지금까지 만든 딥러닝 모델들은 이미지를 구분 하는 정도에 그쳤지만\n",
    "이제 그림을 그리는 뉴럴넷을 만드는데 도전해보려고 합니다.\n",
    "\n",
    "Generative Adversarial Networks,\n",
    "흔히 줄여서 GAN이라 부르고 이안 굿펠로우(Ian Goodfellow)가\n",
    "2014년 처음 제안한 이 방법론은 한국어로 직역하면\n",
    "'적대적 생성 신경망'입니다.\n",
    "왠지 더 어려워보이는 한국어 이름이지만\n",
    "한 단어씩 뜯어보면 그 의미를 알 수 있습니다.\n",
    "\n",
    "먼저 GAN은 '생성'을 하는 모델입니다.\n",
    "기존에 배운 CNN이나 RNN으론 새로운 이미지나 음성을 만들어 낼 수 없었습니다.\n",
    "GAN은 새로운 이미지나 음성을 '창작'할 수 있도록 고안되었습니다.\n",
    "\n",
    "두번째로 GAN은 '적대적'으로 학습합니다. \n",
    "dversarial 이라는 단어를 사전에 찾아보면\n",
    "'서로 대립 관계에 있는', 혹은 '적대적인'이라고 나옵니다.\n",
    "GAN은 가짜 이미지를 생성하는 생성자(Generator)와\n",
    "이미지의 진위 여부를 판별하는 판별자(Discriminator)가\n",
    "연달아 학습을 하며 경쟁적으로 (적대적으로) 학습을 하게 됩니다.\n",
    "\n",
    "마지막으로 GAN은 '신경망'입니다.\n",
    "Generator와 Discrinimator 모두 뉴럴넷으로 되어있습니다.\n",
    "\n",
    "GAN을 한마디로 종합하자면 서로 대립하는\n",
    "두 모델의 경쟁을 통해 학습을 하는 방법론입니다.\n",
    "얀 르쿤 (Yann LeCun)은 이 아이디어를\n",
    "\"근 20년간의 머신러닝 연구 중 가장 재밌는 아이디어\"\n",
    "라고 했고 앤드류 응(Andrew Ng)을 비롯한 많은 연구자들도\n",
    "앞으로 딥러닝을 이끌 기술중 하나라고 진단하고 있습니다.\n",
    "\n",
    "GAN이 이토록 주목받고 미래지향적이라는 평가를 받는\n",
    "이유중 하나는 바로 비지도 학습을 한다는 것입니다.\n",
    "GAN은 앞서 배운 오토인코더와 같이 비지도학습을 합니다.\n",
    "세상에 존재하는 데이터는 기하급수적으로 증가하는 중이고,\n",
    "대부분의 데이터는 정답(label)이 없습니다.\n",
    "그렇다고 사람이 모든 데이터를 일일이 가공하기엔 한계가 많습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0a581ba1f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)    # reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Hyper Parameters\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 100\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"Using Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion MNIST digits dataset\n",
    "trainset = datasets.FashionMNIST('./.data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "       transforms.ToTensor(),\n",
    "       transforms.Normalize((0.5,), (0.5,))\n",
    "    ]))\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = trainset,\n",
    "    batch_size  = BATCH_SIZE,\n",
    "    shuffle     = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "D = nn.Sequential(\n",
    "        nn.Linear(784, 256),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Linear(256, 1),\n",
    "        nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f76404aea14a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m G = nn.Sequential(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# Generator \n",
    "G = nn.Sequential(\n",
    "        nn.Linear(64, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 784),\n",
    "        nn.Tanh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Device setting\n",
    "D = D.to(DEVICE)\n",
    "G = G.to(DEVICE)\n",
    "\n",
    "# Binary cross entropy loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=0.0002)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], Step [200/600], d_loss: 0.0660, g_loss: 4.2427, D(x): 0.99, D(G(z)): 0.05\n",
      "Epoch [0/100], Step [400/600], d_loss: 0.1080, g_loss: 5.2820, D(x): 0.98, D(G(z)): 0.08\n",
      "Epoch [0/100], Step [600/600], d_loss: 0.0489, g_loss: 4.7447, D(x): 0.98, D(G(z)): 0.03\n",
      "Epoch [1/100], Step [200/600], d_loss: 0.0854, g_loss: 3.9816, D(x): 0.98, D(G(z)): 0.05\n",
      "Epoch [1/100], Step [400/600], d_loss: 0.0284, g_loss: 5.3748, D(x): 0.99, D(G(z)): 0.02\n",
      "Epoch [1/100], Step [600/600], d_loss: 0.1014, g_loss: 5.9137, D(x): 0.96, D(G(z)): 0.01\n",
      "Epoch [2/100], Step [200/600], d_loss: 0.0550, g_loss: 5.2941, D(x): 0.98, D(G(z)): 0.02\n",
      "Epoch [2/100], Step [400/600], d_loss: 0.0316, g_loss: 5.7140, D(x): 0.99, D(G(z)): 0.01\n",
      "Epoch [2/100], Step [600/600], d_loss: 0.0235, g_loss: 6.4996, D(x): 0.99, D(G(z)): 0.01\n",
      "Epoch [3/100], Step [200/600], d_loss: 0.0037, g_loss: 12.1831, D(x): 1.00, D(G(z)): 0.00\n",
      "Epoch [3/100], Step [400/600], d_loss: 0.1413, g_loss: 8.5847, D(x): 0.94, D(G(z)): 0.01\n",
      "Epoch [3/100], Step [600/600], d_loss: 0.0718, g_loss: 4.4867, D(x): 0.98, D(G(z)): 0.02\n",
      "Epoch [4/100], Step [200/600], d_loss: 0.0482, g_loss: 6.3989, D(x): 0.99, D(G(z)): 0.02\n",
      "Epoch [4/100], Step [400/600], d_loss: 0.0327, g_loss: 4.3437, D(x): 1.00, D(G(z)): 0.03\n",
      "Epoch [4/100], Step [600/600], d_loss: 0.0898, g_loss: 6.0614, D(x): 0.96, D(G(z)): 0.00\n",
      "Epoch [5/100], Step [200/600], d_loss: 0.1351, g_loss: 6.1474, D(x): 0.95, D(G(z)): 0.01\n",
      "Epoch [5/100], Step [400/600], d_loss: 0.0142, g_loss: 6.0084, D(x): 1.00, D(G(z)): 0.01\n",
      "Epoch [5/100], Step [600/600], d_loss: 0.1693, g_loss: 5.9149, D(x): 0.98, D(G(z)): 0.04\n",
      "Epoch [6/100], Step [200/600], d_loss: 0.1184, g_loss: 8.6821, D(x): 0.96, D(G(z)): 0.02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8abf5decc860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Compute loss with fake images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mfake_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        images = images.reshape(BATCH_SIZE, -1).to(DEVICE)\n",
    "        \n",
    "        # Create the labels which are later used as input for the BCE loss\n",
    "        real_labels = torch.ones(BATCH_SIZE, 1).to(DEVICE)\n",
    "        fake_labels = torch.zeros(BATCH_SIZE, 1).to(DEVICE)\n",
    "\n",
    "        # Train Discriminator\n",
    "\n",
    "        # Compute BCE_Loss using real images where BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n",
    "        # Second term of the loss is always zero since real_labels == 1\n",
    "        outputs = D(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "        \n",
    "        # Compute BCELoss using fake images\n",
    "        # First term of the loss is always zero since fake_labels == 0\n",
    "        z = torch.randn(BATCH_SIZE, 64).to(DEVICE)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # Train Generator\n",
    "\n",
    "        # Compute loss with fake images\n",
    "        z = torch.randn(BATCH_SIZE, 64).to(DEVICE)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        \n",
    "        # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n",
    "        # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        if (i+1) % 200 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
    "                  .format(epoch, EPOCHS, i+1, total_step, d_loss.item(), g_loss.item(), \n",
    "                          real_score.mean().item(), fake_score.mean().item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고\n",
    "본 튜토리얼은 다음 자료를 참고하여 만들어졌습니다.\n",
    "\n",
    "* [yunjey/pytorch-tutorial](https://github.com/yunjey/pytorch-tutorial) - MIT License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
